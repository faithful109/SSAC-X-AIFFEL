{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장의 사전적 정의: 생각이나 감정을 말과 글로 표현할 때 완결된 내용을 나타내는 최소의 단위  \n",
    "시퀀스란 데이터에 순서를 붙여 하나씩 나열한 것. 특정 위치의 데이터를 가리킬 수 있다. ex) 리스트, 튜플, 레인지, 문자열  \n",
    "문법을 배워서 인공지능이 문장을 예측할 수 없으니 통계적인 접근방법 선택! -> 많은 데이터가 곧 좋은 결과 ->가장 좋은 인공지능이 RNN(순환신경망)  \n",
    "통계적인 이라는 뜻은 대체로 \\~~하다라고 생각하면 된다  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 문장: <start> 나는 밥을 먹었다 \n",
      "Target 문장:  나는 밥을 먹었다 <end>\n"
     ]
    }
   ],
   "source": [
    "#첫 시작은 <start>라는 토큰으로 표시. 끝은 <end>라는 토큰으로 표시  \n",
    "#<start>가 문장의 시작인 입력데이터와 <end>가 문장의 끝인 출력데이터가 필요.\n",
    "sentence = \" 나는 밥을 먹었다 \"\n",
    "\n",
    "source_sentence = \"<start>\" + sentence\n",
    "target_sentence = sentence + \"<end>\"\n",
    "\n",
    "print(\"Source 문장:\", source_sentence)\n",
    "print(\"Target 문장:\", target_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n-1개의 단어 시퀀스가 주어질 때 n번쨰 단어가 뭐일지 예측하는 확률모델을 언어모델.  \n",
    "파라미터 θ로 모델링하는 언어모델  \n",
    "<img src=\"수식.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n-1까지의 단어 시퀀스가 x_train, n번째가 y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['First Citizen:', 'Before we proceed any further, hear me speak.', '', 'All:', 'Speak, speak.', '', 'First Citizen:', 'You are all resolved rather to die than to famish?', '']\n"
     ]
    }
   ],
   "source": [
    "import re                  # 정규표현식을 위한 Regex 지원 모듈 (문장 데이터를 정돈하기 위해) \n",
    "import numpy as np         # 변환된 문장 데이터(행렬)을 편하게 처리하기 위해\n",
    "import tensorflow as tf    # 대망의 텐서플로우!\n",
    "import os\n",
    "\n",
    "# 파일을 읽기모드로 열어 봅니다.\n",
    "file_path = os.getenv('HOME') + '/aiffel/lyricist/data/shakespeare.txt'\n",
    "with open(file_path, \"r\") as f: # with문을 사용하면 with 블록을 벗어나는 순간 열린 파일 객체 f가 자동으로 close되어 편리하다.\n",
    "    raw_corpus = f.read().splitlines()   # 텍스트를 라인 단위로 끊어서 list 형태로 읽어옵니다.\n",
    "\n",
    "print(raw_corpus[:9])    # 앞에서부터 10라인만 화면에 출력해 볼까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "화자 표기된 곳: 0, 3, 6  \n",
    "공백: 2, 5, 9  \n",
    "쓸모없는 데이터 처리!  \n",
    "<img src=\"셰익스피어.png\" align=\"left\">  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before we proceed any further, hear me speak.\n",
      "Speak, speak.\n",
      "You are all resolved rather to die than to famish?\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
    "    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장은 건너뜁니다.\n",
    "\n",
    "    if idx > 9: break   # 일단 문장 10개만 확인해 볼 겁니다.\n",
    "        \n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장을 쪼개는 것을 토근화라고 한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()       # 소문자로 바꾸고 양쪽 공백을 삭제\n",
    "  \n",
    "    # 아래 3단계를 거쳐 sentence는 스페이스 1개를 delimeter로 하는 소문자 단어 시퀀스로 바뀝니다.\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)        # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)                  # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자(공백문자까지도)를 스페이스 1개로 치환\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    sentence = '<start> ' + sentence + ' <end>'      # 이전 스텝에서 본 것처럼 문장 앞뒤로 <start>와 <end>를 단어처럼 붙여 줍니다\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))   # 이 문장이 어떻게 필터링되는지 확인해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "델의 입력이 되는 문장을 소스 문장(Source Sentence)(X_train), 정답 역할을 하게 될 모델의 출력 문장을 타겟 문장(Target Sentence)(y_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> before we proceed any further , hear me speak . <end>',\n",
       " '<start> speak , speak . <end>',\n",
       " '<start> you are all resolved rather to die than to famish ? <end>',\n",
       " '<start> resolved . resolved . <end>',\n",
       " '<start> first , you know caius marcius is chief enemy to the people . <end>',\n",
       " '<start> we know t , we know t . <end>',\n",
       " '<start> let us kill him , and we ll have corn at our own price . <end>',\n",
       " '<start> is t a verdict ? <end>',\n",
       " '<start> no more talking on t let it be done away , away ! <end>',\n",
       " '<start> one word , good citizens . <end>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "        \n",
    "    corpus.append(preprocess_sentence(sentence))\n",
    "        \n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 가르칠 데이터는 숫자로 전달해야 함으로. 딕셔너리에 데이터를 숫자로 변환.(이 과정을 벡터화), 숫자로 변환된 데이터를 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2  143   40 ...    0    0    0]\n",
      " [   2  110    4 ...    0    0    0]\n",
      " [   2   11   50 ...    0    0    0]\n",
      " ...\n",
      " [   2  149 4553 ...    0    0    0]\n",
      " [   2   34   71 ...    0    0    0]\n",
      " [   2  945   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f979361d990>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    # 텐서플로우에서 제공하는 Tokenizer 패키지를 생성\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=7000,  # 전체 단어의 개수 \n",
    "        filters=' ',    # 별도로 전처리 로직을 추가할 수 있습니다. 이번에는 사용하지 않겠습니다.\n",
    "        oov_token=\"<unk>\"  # out-of-vocabulary, 사전에 없었던 단어는 어떤 토큰으로 대체할지\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)   # 우리가 구축한 corpus로부터 Tokenizer가 사전을 자동구축하게 됩니다.\n",
    "\n",
    "    # 이후 tokenizer를 활용하여 모델에 입력할 데이터셋을 구축하게 됩니다.\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   # tokenizer는 구축한 사전으로부터 corpus를 해석해 Tensor로 변환합니다.\n",
    "\n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞추기 위한 padding  메소드를 제공합니다.\n",
    "    # maxlen의 디폴트값은 None입니다. 이 경우 corpus의 가장 긴 문장을 기준으로 시퀀스 길이가 맞춰집니다.\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "\n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2  143   40  933  140  591    4  124   24  110]\n",
      " [   2  110    4  110    5    3    0    0    0    0]\n",
      " [   2   11   50   43 1201  316    9  201   74    9]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor[:3, :10])\n",
    "#출력값이 0으로 나온 부분은 패딩이 들어간 것으로 길이를 맞추기 위해 넣은것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : .\n",
      "6 : the\n",
      "7 : and\n",
      "8 : i\n",
      "9 : to\n",
      "10 : of\n"
     ]
    }
   ],
   "source": [
    "#텐서 데이터는 모두 정수로 구성. 이 숫자는 tokenizer에 구축된 단어사전의 인덱스\n",
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24015, 21)\n",
      "[  2 143  40 933 140 591   4 124  24 110   5   3   0   0   0   0   0   0\n",
      "   0   0]\n",
      "(24015, 20)\n",
      "[143  40 933 140 591   4 124  24 110   5   3   0   0   0   0   0   0   0\n",
      "   0   0]\n"
     ]
    }
   ],
   "source": [
    "#생성된 텐서를 소스와 타겟으로 분리.\n",
    "print(tensor.shape)\n",
    "src_input = tensor[:, :-1]  # tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다. 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "tgt_input = tensor[:, 1:]    # tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "\n",
    "print(src_input[0])\n",
    "print(src_input.shape)\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 20), (256, 20)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1    # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로 데이터셋 생성과정  \n",
    "1.정규표현식을 이용한 corpus생성  \n",
    "2.tf.keras.preprocessing.text.Tokenizer를 이용해 corpus -> tensor  \n",
    "3.tf.data.Dataset.from_tensor_slices()를 이용해 corpus 텐서 -> tf.data.Dataset  \n",
    "위의 과정을 텐서플로의 데이터 전처리라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 만들 모델은 tf.keras.Model을 subclassing.  \n",
    "Embedding레이어 1개, LSTM레이어 2개, Dense레이어 1개로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
    "#Embedding 레이어가 단어사전의 인덱스를 해당 인덱스의 워드벡터로 바꿔준다.\n",
    "#embedding_size는 워드벡터의 차원수. 값이 커질 수록 추상적인 특징을 잡을 수 있지만, 그만큼 충분한 데이터가 필요.\n",
    "#LSTM레이어의 hidden state의 차원수인 hidden_size도 같은 역할.모델에 얼마나 많은 일꾼을 쓸것인지 결정.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 20, 7001), dtype=float32, numpy=\n",
       "array([[[-1.5287522e-04,  3.5295959e-04, -4.9959397e-04, ...,\n",
       "          4.6026160e-04, -4.4646331e-05, -3.3868867e-04],\n",
       "        [-1.6363825e-04,  5.7893735e-04, -6.7387172e-04, ...,\n",
       "          3.0235498e-04, -1.3928095e-04, -5.8676355e-04],\n",
       "        [ 1.4312154e-04,  6.3640939e-04, -4.9666391e-04, ...,\n",
       "          2.5546073e-04, -1.8916781e-04, -4.9723283e-04],\n",
       "        ...,\n",
       "        [-2.4677252e-03,  5.4253044e-04,  3.4631770e-03, ...,\n",
       "          4.4178432e-03,  6.9964339e-04, -2.0891894e-03],\n",
       "        [-2.6790332e-03,  5.0510722e-04,  4.0180958e-03, ...,\n",
       "          4.9024201e-03,  7.8489422e-04, -2.2059935e-03],\n",
       "        [-2.8626632e-03,  4.5343651e-04,  4.5104185e-03, ...,\n",
       "          5.3202952e-03,  8.6191756e-04, -2.2843801e-03]],\n",
       "\n",
       "       [[-1.5287522e-04,  3.5295959e-04, -4.9959397e-04, ...,\n",
       "          4.6026160e-04, -4.4646331e-05, -3.3868867e-04],\n",
       "        [-2.0027682e-04,  3.4450230e-04, -6.9246389e-04, ...,\n",
       "          6.8491843e-04, -3.3317058e-04, -3.2553836e-04],\n",
       "        [-2.1523006e-04,  1.5147730e-04, -6.8587647e-04, ...,\n",
       "          7.3612767e-04, -1.0849780e-03, -7.0160779e-04],\n",
       "        ...,\n",
       "        [-2.5700952e-03,  1.7681801e-04,  5.5807666e-03, ...,\n",
       "          6.3540535e-03,  1.1052438e-03, -2.3969943e-03],\n",
       "        [-2.7527260e-03,  1.2935609e-04,  5.8802539e-03, ...,\n",
       "          6.5350337e-03,  1.1590072e-03, -2.3585183e-03],\n",
       "        [-2.9223016e-03,  6.8621062e-05,  6.1309445e-03, ...,\n",
       "          6.6789980e-03,  1.2082723e-03, -2.3135927e-03]],\n",
       "\n",
       "       [[-1.5287522e-04,  3.5295959e-04, -4.9959397e-04, ...,\n",
       "          4.6026160e-04, -4.4646331e-05, -3.3868867e-04],\n",
       "        [-4.7172059e-04,  7.0824067e-04, -9.1975235e-04, ...,\n",
       "          1.0120844e-03,  3.5201080e-04, -5.1451375e-04],\n",
       "        [-8.8647328e-04,  1.0401479e-03, -1.2537580e-03, ...,\n",
       "          1.3925841e-03,  8.0477918e-04, -6.7672686e-04],\n",
       "        ...,\n",
       "        [-1.1199700e-03,  6.5793644e-04,  4.4722660e-03, ...,\n",
       "          4.5640217e-03,  9.1062026e-04, -1.4349830e-03],\n",
       "        [-1.4015951e-03,  6.5851083e-04,  4.9185422e-03, ...,\n",
       "          5.0077918e-03,  9.6992491e-04, -1.6411894e-03],\n",
       "        [-1.6771147e-03,  6.2836951e-04,  5.3051971e-03, ...,\n",
       "          5.3943270e-03,  1.0223325e-03, -1.7995656e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.5287522e-04,  3.5295959e-04, -4.9959397e-04, ...,\n",
       "          4.6026160e-04, -4.4646331e-05, -3.3868867e-04],\n",
       "        [-4.6215692e-04,  4.1646730e-05, -1.2523641e-03, ...,\n",
       "          5.4833078e-04, -1.3034149e-04, -5.9053657e-04],\n",
       "        [-2.3848972e-04, -2.0958290e-04, -1.7824263e-03, ...,\n",
       "          5.7971402e-04,  6.2839819e-05, -4.5212504e-04],\n",
       "        ...,\n",
       "        [-7.7285781e-04, -1.9989304e-04,  3.6288146e-03, ...,\n",
       "          4.3361126e-03,  5.0134055e-04, -2.2853932e-03],\n",
       "        [-9.9165970e-04, -5.5451277e-05,  4.1966876e-03, ...,\n",
       "          4.8238002e-03,  5.4302369e-04, -2.3497860e-03],\n",
       "        [-1.2348457e-03,  4.3830652e-05,  4.6909084e-03, ...,\n",
       "          5.2576121e-03,  5.8910548e-04, -2.3925998e-03]],\n",
       "\n",
       "       [[-1.5287522e-04,  3.5295959e-04, -4.9959397e-04, ...,\n",
       "          4.6026160e-04, -4.4646331e-05, -3.3868867e-04],\n",
       "        [-1.5657651e-04,  5.9772236e-04, -7.6850184e-04, ...,\n",
       "          1.1419782e-03, -2.2832610e-04, -4.1803680e-04],\n",
       "        [-4.9284765e-05,  6.8385468e-04, -8.4289000e-04, ...,\n",
       "          1.5065772e-03, -2.2186794e-04, -2.6939664e-04],\n",
       "        ...,\n",
       "        [ 2.4708992e-04, -2.6234773e-03,  1.9547790e-03, ...,\n",
       "          1.7008502e-03, -1.9424102e-04, -1.4866681e-03],\n",
       "        [ 6.0090683e-06, -2.2127742e-03,  2.6249234e-03, ...,\n",
       "          2.3227818e-03, -1.4133297e-05, -1.7539450e-03],\n",
       "        [-2.6993014e-04, -1.8053957e-03,  3.2707804e-03, ...,\n",
       "          2.9496718e-03,  1.3253448e-04, -1.9833748e-03]],\n",
       "\n",
       "       [[-1.5287522e-04,  3.5295959e-04, -4.9959397e-04, ...,\n",
       "          4.6026160e-04, -4.4646331e-05, -3.3868867e-04],\n",
       "        [-3.6411564e-04,  2.4517419e-04, -9.0122013e-04, ...,\n",
       "          8.5730152e-04,  3.3768451e-05, -6.8133662e-04],\n",
       "        [-7.7746058e-04,  4.3906810e-04, -8.2013919e-04, ...,\n",
       "          1.2713311e-03,  3.0683138e-04, -4.7080382e-04],\n",
       "        ...,\n",
       "        [ 1.9196181e-05, -1.0390307e-03,  7.4988190e-04, ...,\n",
       "          2.3743282e-03, -5.9599064e-05, -1.3332675e-03],\n",
       "        [-1.8551329e-04, -8.3550526e-04,  1.4235822e-03, ...,\n",
       "          2.9312808e-03,  1.5458702e-04, -1.6238901e-03],\n",
       "        [-4.2096339e-04, -6.3403265e-04,  2.0977638e-03, ...,\n",
       "          3.5025501e-03,  3.2674620e-04, -1.8757855e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "model(src_sample)\n",
    "#model의 input shape가 결정되면서 model.build()가 자동으로 호출됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor 출력 shape가 256, 20, 7001이다.  \n",
    "7001은 dense레이어의 출력 차원.(즉, 7001의 단어가 나올 수 있다, 각 단어의 확률)  \n",
    "256은 이전 스텝에서 지정한 배치 사이즈입니다. dataset.take(1)를 통해서 1개의 배치를 가져옴.\n",
    "20은 tf.keras.layers.LSTM(hidden_size, return_sequences=True)로 호출한 LSTM 레이어에서 return_sequences=True에서 자신에게 입력된 시퀀스길이만큼 동일한 길이의 시퀀스를 출력. return_sequences=False일경우 vector 1개만 출력.  \n",
    "우리 데이터 셋의 len가 20으로 맞춰져있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  1792256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  7176025   \n",
      "=================================================================\n",
      "Total params: 22,607,961\n",
      "Trainable params: 22,607,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "93/93 [==============================] - 14s 156ms/step - loss: 3.4982\n",
      "Epoch 2/30\n",
      "93/93 [==============================] - 15s 157ms/step - loss: 2.8132\n",
      "Epoch 3/30\n",
      "93/93 [==============================] - 15s 158ms/step - loss: 2.7286\n",
      "Epoch 4/30\n",
      "93/93 [==============================] - 15s 159ms/step - loss: 2.6359\n",
      "Epoch 5/30\n",
      "93/93 [==============================] - 15s 161ms/step - loss: 2.5676\n",
      "Epoch 6/30\n",
      "93/93 [==============================] - 15s 160ms/step - loss: 2.5170\n",
      "Epoch 7/30\n",
      "93/93 [==============================] - 15s 160ms/step - loss: 2.4749\n",
      "Epoch 8/30\n",
      "93/93 [==============================] - 15s 160ms/step - loss: 2.4303\n",
      "Epoch 9/30\n",
      "93/93 [==============================] - 15s 160ms/step - loss: 2.3850\n",
      "Epoch 10/30\n",
      "93/93 [==============================] - 15s 161ms/step - loss: 2.3439\n",
      "Epoch 11/30\n",
      "93/93 [==============================] - 15s 160ms/step - loss: 2.3018\n",
      "Epoch 12/30\n",
      "93/93 [==============================] - 15s 161ms/step - loss: 2.2599\n",
      "Epoch 13/30\n",
      "93/93 [==============================] - 15s 161ms/step - loss: 2.2181\n",
      "Epoch 14/30\n",
      "93/93 [==============================] - 15s 161ms/step - loss: 2.1775\n",
      "Epoch 15/30\n",
      "93/93 [==============================] - 15s 161ms/step - loss: 2.1384\n",
      "Epoch 16/30\n",
      "93/93 [==============================] - 15s 161ms/step - loss: 2.1004\n",
      "Epoch 17/30\n",
      "93/93 [==============================] - 15s 161ms/step - loss: 2.0627\n",
      "Epoch 18/30\n",
      "93/93 [==============================] - 15s 160ms/step - loss: 2.0250\n",
      "Epoch 19/30\n",
      "93/93 [==============================] - 15s 161ms/step - loss: 1.9866\n",
      "Epoch 20/30\n",
      "93/93 [==============================] - 15s 162ms/step - loss: 1.9476\n",
      "Epoch 21/30\n",
      "93/93 [==============================] - 15s 161ms/step - loss: 1.9106\n",
      "Epoch 22/30\n",
      "93/93 [==============================] - 15s 160ms/step - loss: 1.8745\n",
      "Epoch 23/30\n",
      "93/93 [==============================] - 15s 161ms/step - loss: 1.8357\n",
      "Epoch 24/30\n",
      "93/93 [==============================] - 15s 161ms/step - loss: 1.7968\n",
      "Epoch 25/30\n",
      "93/93 [==============================] - 15s 161ms/step - loss: 1.7602\n",
      "Epoch 26/30\n",
      "93/93 [==============================] - 15s 161ms/step - loss: 1.7212\n",
      "Epoch 27/30\n",
      "93/93 [==============================] - 15s 161ms/step - loss: 1.6838\n",
      "Epoch 28/30\n",
      "93/93 [==============================] - 15s 160ms/step - loss: 1.6471\n",
      "Epoch 29/30\n",
      "93/93 [==============================] - 15s 163ms/step - loss: 1.6106\n",
      "Epoch 30/30\n",
      "93/93 [==============================] - 15s 160ms/step - loss: 1.5735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f96f00ea2d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "model.fit(dataset, epochs=30)\n",
    "#loss값이 감소하고 있기에 학습이 잘 진행되고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#성능 확인을 위해 작문을 시켜보고, 평가!\n",
    "#아래 함수는 시작 문장을 바탕으로 작문시작.\n",
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환합니다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 텍스트를 실제로 생성할때는 루프를 돌면서 단어 하나씩 생성해야 합니다. \n",
    "    while True:\n",
    "        predict = model(test_tensor)  # 입력받은 문장의 텐서를 입력합니다. \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   # 우리 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됩니다. \n",
    "\n",
    "        # 우리 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙여 줍니다. \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 우리 모델이 <end>를 예측했거나, max_len에 도달하지 않았다면  while 루프를 또 돌면서 다음 단어를 예측해야 합니다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   # 이것이 최종적으로 모델이 생성한 자연어 문장입니다.\n",
    "#while문을 통해 문장생성.\n",
    "#텍스트 생성시 타겟문장이 없고, 소스문장이 없다. 그냥 학습시킨 걸 기반으로 만든다.\n",
    "#init_sentence를 인자로 받아 텐서로 변환.\n",
    "# <start>\n",
    "# <start> Hi\n",
    "# <start> Hi my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> he is not lolling on the <unk> s face , <end> '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> he\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로젝트 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['[Hook]', \"I've been down so long, it look like up to me\", 'They look up to me']\n"
     ]
    }
   ],
   "source": [
    "import glob # glob를 이용하여 모든 txt 파일을 읽음.\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines() #문장단위로 저장\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
    "    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장은 건너뜁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()       # 소문자로 바꾸고 양쪽 공백을 삭제\n",
    "  \n",
    "    # 아래 3단계를 거쳐 sentence는 스페이스 1개를 delimeter로 하는 소문자 단어 시퀀스로 바뀝니다.\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)        # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)                  # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자(공백문자까지도)를 스페이스 1개로 치환\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    sentence = '<start> ' + sentence + ' <end>'      # 이전 스텝에서 본 것처럼 문장 앞뒤로 <start>와 <end>를 단어처럼 붙여 줍니다\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))   # 이 문장이 어떻게 필터링되는지 확인해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175749\n",
      "['<start> hook <end>', '<start> i ve been down so long , it look like up to me <end>', '<start> they look up to me <end>', '<start> i got fake people showin fake love to me <end>', '<start> straight up to my face , straight up to my face <end>', '<start> i ve been down so long , it look like up to me <end>', '<start> they look up to me <end>', '<start> i got fake people showin fake love to me <end>', '<start> straight up to my face , straight up to my face verse <end>', '<start> somethin ain t right when we talkin <end>']\n",
      "156012\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "after_corpus = []\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "        \n",
    "    corpus.append(preprocess_sentence(sentence))\n",
    "\n",
    "print(len(corpus))        \n",
    "print(corpus[:10])\n",
    "\n",
    "for i in range((len(corpus))-1):\n",
    "    if len(corpus[i].split(' ')) <16:\n",
    "        after_corpus.append(corpus[i])\n",
    "corpus = after_corpus\n",
    "\n",
    "print(len(corpus)) \n",
    "src_input = tensor[:, :-1]\n",
    "tgt_input = tensor[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2 966   3 ...   0   0   0]\n",
      " [  2   4  95 ...  10  12   3]\n",
      " [  2  38 133 ...   0   0   0]\n",
      " ...\n",
      " [  2  47  47 ...   0   0   0]\n",
      " [  2   3   0 ...   0   0   0]\n",
      " [  2   3   0 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7f969478d810>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    # 텐서플로우에서 제공하는 Tokenizer 패키지를 생성\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000,  # 전체 단어의 개수 \n",
    "        filters=' ',    # 별도로 전처리 로직을 추가할 수 있습니다. 이번에는 사용하지 않겠습니다.\n",
    "        oov_token=\"<unk>\"  # out-of-vocabulary, 사전에 없었던 단어는 어떤 토큰으로 대체할지\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)   # 우리가 구축한 corpus로부터 Tokenizer가 사전을 자동구축하게 됩니다.\n",
    "\n",
    "    # 이후 tokenizer를 활용하여 모델에 입력할 데이터셋을 구축하게 됩니다.\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   # tokenizer는 구축한 사전으로부터 corpus를 해석해 Tensor로 변환합니다.\n",
    "\n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞추기 위한 padding  메소드를 제공합니다.\n",
    "    # maxlen의 디폴트값은 None입니다. 이 경우 corpus의 가장 긴 문장을 기준으로 시퀀스 길이가 맞춰집니다.\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "\n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (124809, 14)\n",
      "Target Train: (124809, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input,tgt_input,train_size = 0.8)\n",
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1    # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
    "#Embedding 레이어가 단어사전의 인덱스를 해당 인덱스의 워드벡터로 바꿔준다.\n",
    "#embedding_size는 워드벡터의 차원수. 값이 커질 수록 추상적인 특징을 잡을 수 있지만, 그만큼 충분한 데이터가 필요.\n",
    "#LSTM레이어의 hidden state의 차원수인 hidden_size도 같은 역할.모델에 얼마나 많은 일꾼을 쓸것인지 결정.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[-1.69407082e-04,  2.34630235e-04,  8.27339463e-05, ...,\n",
       "         -3.22848471e-04,  1.62889410e-05,  2.24639021e-04],\n",
       "        [-5.09555975e-04,  3.94151779e-04,  1.80705192e-05, ...,\n",
       "         -2.57879437e-04, -2.87380885e-06,  5.45676507e-04],\n",
       "        [-6.14647055e-04,  5.55543229e-04,  1.91670388e-05, ...,\n",
       "         -3.33313888e-04,  1.72477608e-04,  5.56239625e-04],\n",
       "        ...,\n",
       "        [-1.15552742e-03, -9.11077252e-04, -6.47684501e-04, ...,\n",
       "         -3.42394778e-04, -4.04188177e-04,  4.22295579e-06],\n",
       "        [-1.22184074e-03, -1.27720379e-03, -9.00728279e-04, ...,\n",
       "         -1.82931355e-04, -9.12488671e-04,  1.15402312e-04],\n",
       "        [-1.21427677e-03, -1.63967477e-03, -1.21179968e-03, ...,\n",
       "         -9.38154626e-05, -1.40621921e-03,  3.24869936e-04]],\n",
       "\n",
       "       [[-1.69407082e-04,  2.34630235e-04,  8.27339463e-05, ...,\n",
       "         -3.22848471e-04,  1.62889410e-05,  2.24639021e-04],\n",
       "        [-3.50807735e-04,  1.72908258e-04,  1.88477075e-04, ...,\n",
       "         -5.37759566e-04,  1.03511549e-04,  2.49788864e-04],\n",
       "        [-4.91763582e-04,  4.27113300e-05,  1.69123945e-04, ...,\n",
       "         -5.95243881e-04,  3.40526749e-04,  3.25425935e-04],\n",
       "        ...,\n",
       "        [-2.04040995e-03,  7.09645625e-04, -2.43034388e-04, ...,\n",
       "         -8.34415143e-04,  1.21490948e-03,  5.68033371e-04],\n",
       "        [-1.94873626e-03,  6.49170601e-04, -4.67204431e-04, ...,\n",
       "         -1.09460345e-03,  1.34325319e-03,  5.89530275e-04],\n",
       "        [-1.99876982e-03,  5.76103688e-04, -6.53210038e-04, ...,\n",
       "         -1.08333048e-03,  1.37607916e-03,  5.87162795e-04]],\n",
       "\n",
       "       [[-1.69407082e-04,  2.34630235e-04,  8.27339463e-05, ...,\n",
       "         -3.22848471e-04,  1.62889410e-05,  2.24639021e-04],\n",
       "        [-5.65963448e-04,  3.66899563e-04,  9.02444226e-05, ...,\n",
       "         -7.15313130e-04, -5.55281804e-05,  2.08129350e-04],\n",
       "        [-9.83682694e-04,  3.37348436e-04,  3.40316474e-04, ...,\n",
       "         -9.24675143e-04, -1.88797479e-04,  3.00183514e-04],\n",
       "        ...,\n",
       "        [-1.25448522e-03, -7.97586865e-04,  3.27358459e-04, ...,\n",
       "          4.06200124e-04, -2.57023843e-03,  1.10106822e-03],\n",
       "        [-1.20106281e-03, -1.21076964e-03, -2.30918798e-04, ...,\n",
       "          3.91124602e-04, -2.87484890e-03,  1.32864225e-03],\n",
       "        [-1.11445936e-03, -1.58859417e-03, -7.96849839e-04, ...,\n",
       "          3.18267004e-04, -3.15112504e-03,  1.59063085e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.69407082e-04,  2.34630235e-04,  8.27339463e-05, ...,\n",
       "         -3.22848471e-04,  1.62889410e-05,  2.24639021e-04],\n",
       "        [-2.03860691e-04,  1.63470904e-04,  4.38221788e-04, ...,\n",
       "         -2.44262425e-04,  3.90256231e-04,  3.53203272e-04],\n",
       "        [-3.47463501e-04,  3.58959514e-04,  3.97694152e-04, ...,\n",
       "         -3.39009654e-04,  8.63792608e-04,  4.97524568e-04],\n",
       "        ...,\n",
       "        [-3.20501567e-04, -1.82659610e-03, -2.14987155e-03, ...,\n",
       "          1.32944508e-04, -1.69253338e-03,  1.52498542e-03],\n",
       "        [-2.65164825e-04, -2.19587493e-03, -2.53964216e-03, ...,\n",
       "         -2.12758696e-05, -2.10325955e-03,  1.83806755e-03],\n",
       "        [-2.08059064e-04, -2.54128315e-03, -2.90619954e-03, ...,\n",
       "         -1.71311302e-04, -2.45881593e-03,  2.14888854e-03]],\n",
       "\n",
       "       [[-1.69407082e-04,  2.34630235e-04,  8.27339463e-05, ...,\n",
       "         -3.22848471e-04,  1.62889410e-05,  2.24639021e-04],\n",
       "        [-6.71785616e-04,  2.46514799e-04, -2.61946916e-05, ...,\n",
       "         -6.00739208e-04,  2.70701159e-04,  2.62914895e-04],\n",
       "        [-7.47347367e-04,  2.00138355e-04,  6.46321205e-05, ...,\n",
       "         -4.16460476e-04,  6.34289696e-04,  2.52991071e-04],\n",
       "        ...,\n",
       "        [-1.39772415e-03, -1.99595909e-03, -1.52948266e-03, ...,\n",
       "          8.57535168e-04, -2.09675590e-03,  1.18912233e-03],\n",
       "        [-1.27049698e-03, -2.27920734e-03, -1.97843672e-03, ...,\n",
       "          6.80287078e-04, -2.46274751e-03,  1.52767648e-03],\n",
       "        [-1.13672565e-03, -2.55504623e-03, -2.40965653e-03, ...,\n",
       "          4.84603021e-04, -2.77218781e-03,  1.86614890e-03]],\n",
       "\n",
       "       [[-1.69407082e-04,  2.34630235e-04,  8.27339463e-05, ...,\n",
       "         -3.22848471e-04,  1.62889410e-05,  2.24639021e-04],\n",
       "        [-2.62974878e-04,  1.83094468e-04,  7.26787994e-06, ...,\n",
       "         -5.51588542e-04,  8.33532758e-05,  1.92925130e-04],\n",
       "        [-5.29396173e-04,  1.65218793e-04, -1.33021138e-04, ...,\n",
       "         -4.34556947e-04,  1.05846600e-04,  3.40599101e-04],\n",
       "        ...,\n",
       "        [-6.49960886e-04, -2.36870116e-03, -2.23177322e-03, ...,\n",
       "          1.50804306e-04, -2.39928090e-03,  1.30593369e-03],\n",
       "        [-5.63804526e-04, -2.65177549e-03, -2.61770631e-03, ...,\n",
       "          2.55646246e-05, -2.72797281e-03,  1.68425264e-03],\n",
       "        [-4.80840798e-04, -2.92271329e-03, -2.98504415e-03, ...,\n",
       "         -1.06990476e-04, -3.00753233e-03,  2.05240073e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "609/609 [==============================] - 87s 143ms/step - loss: 3.4139\n",
      "Epoch 2/10\n",
      "609/609 [==============================] - 89s 146ms/step - loss: 2.9661\n",
      "Epoch 3/10\n",
      "609/609 [==============================] - 90s 148ms/step - loss: 2.7988\n",
      "Epoch 4/10\n",
      "609/609 [==============================] - 90s 148ms/step - loss: 2.6700\n",
      "Epoch 5/10\n",
      "609/609 [==============================] - 91s 149ms/step - loss: 2.5607\n",
      "Epoch 6/10\n",
      "609/609 [==============================] - 91s 149ms/step - loss: 2.4628\n",
      "Epoch 7/10\n",
      "609/609 [==============================] - 91s 149ms/step - loss: 2.3730\n",
      "Epoch 8/10\n",
      "609/609 [==============================] - 91s 149ms/step - loss: 2.2897\n",
      "Epoch 9/10\n",
      "609/609 [==============================] - 91s 149ms/step - loss: 2.2119\n",
      "Epoch 10/10\n",
      "609/609 [==============================] - 91s 150ms/step - loss: 2.1387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f96856ef250>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "model.fit(dataset, epochs=10)\n",
    "#loss값이 감소하고 있기에 학습이 잘 진행되고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#성능 확인을 위해 작문을 시켜보고, 평가!\n",
    "#아래 함수는 시작 문장을 바탕으로 작문시작.\n",
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환합니다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 텍스트를 실제로 생성할때는 루프를 돌면서 단어 하나씩 생성해야 합니다. \n",
    "    while True:\n",
    "        predict = model(test_tensor)  # 입력받은 문장의 텐서를 입력합니다. \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   # 우리 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됩니다. \n",
    "\n",
    "        # 우리 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙여 줍니다. \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 우리 모델이 <end>를 예측했거나, max_len에 도달하지 않았다면  while 루프를 또 돌면서 다음 단어를 예측해야 합니다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   # 이것이 최종적으로 모델이 생성한 자연어 문장입니다.\n",
    "#while문을 통해 문장생성.\n",
    "#텍스트 생성시 타겟문장이 없고, 소스문장이 없다. 그냥 학습시킨 걸 기반으로 만든다.\n",
    "#init_sentence를 인자로 받아 텐서로 변환.\n",
    "# <start>\n",
    "# <start> Hi\n",
    "# <start> Hi my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , liberian girl <end> '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
